{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we will work with totImages images\n",
    "totImages = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fn = glob.glob(\"VOC2012/Annotations/*\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images = dict()\n",
    "cat = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done parsing in  0.144268989563  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for f in fn:\n",
    "    cnt = cnt + 1\n",
    "    if cnt > totImages:\n",
    "        break\n",
    "    \n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    curFile = \"\"\n",
    "    for child in root:\n",
    "        if child.tag == 'filename':\n",
    "            curFile = child.text\n",
    "    images[curFile] = []\n",
    "    \n",
    "    for child in root:\n",
    "        if child.tag == 'object':\n",
    "            for child2 in child:\n",
    "                if child2.tag == 'name':\n",
    "                    images[curFile].append(child2.text)\n",
    "                    cat.add(child2.text)\n",
    "                    \n",
    "print 'Done parsing in ', time.time() - start, \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sheep', 'horse', 'bicycle', 'bottle', 'cow', 'sofa', 'dog', 'bus', 'cat', 'person', 'train', 'diningtable', 'aeroplane', 'car', 'pottedplant', 'tvmonitor', 'chair', 'bird', 'boat', 'motorbike']\n"
     ]
    }
   ],
   "source": [
    "cat = list(cat)\n",
    "print cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2007_002618.jpg', '2007_001872.jpg', '2007_000925.jpg', '2007_000676.jpg', '2007_001733.jpg']\n"
     ]
    }
   ],
   "source": [
    "catimg = dict()\n",
    "for curCat in cat:\n",
    "    catimg[curCat] = []\n",
    "\n",
    "for img in images:\n",
    "    for curCat in set(images[img]):\n",
    "        catimg[curCat].append(img)\n",
    "        \n",
    "print catimg['sheep'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007_001154.jpg ['sofa', 'pottedplant']\n",
      "2007_001154.jpg [0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      "\n",
      "2007_000645.jpg ['bird', 'bird']\n",
      "2007_000645.jpg [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0]\n",
      "\n",
      "2007_002284.jpg ['pottedplant', 'pottedplant', 'pottedplant', 'pottedplant', 'pottedplant', 'pottedplant']\n",
      "2007_002284.jpg [0 0 0 0 0 0 0 0 0 0 0 0 0 0 6 0 0 0 0 0]\n",
      "\n",
      "2007_000061.jpg ['boat', 'boat']\n",
      "2007_000061.jpg [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      "\n",
      "2007_002344.jpg ['person']\n",
      "2007_002344.jpg [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "featvec = images.copy()\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for img in images:\n",
    "    cnt = cnt + 1\n",
    "    if cnt <= 5:\n",
    "        print img, images[img]\n",
    "    \n",
    "    features = featvec[img]\n",
    "    \n",
    "    featvec[img] = [0 for i in range(len(cat))]\n",
    "    for f in features:\n",
    "        for j in range(len(cat)):\n",
    "            if cat[j] == f:\n",
    "                featvec[img][j] = featvec[img][j] + 1\n",
    "                break\n",
    "                \n",
    "    featvec[img] = np.array(featvec[img])\n",
    "                \n",
    "    if cnt <= 5:\n",
    "        print img, featvec[img]\n",
    "        print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute a dictionary of norms and normdistances\n",
    "nrm = featvec.copy()\n",
    "for elem in nrm:\n",
    "    nrm[elem] = np.linalg.norm(nrm[elem])\n",
    "\n",
    "nrmdist = dict()\n",
    "for el1 in featvec:\n",
    "    for el2 in featvec:\n",
    "        nrmdist[(el1, el2)] = np.linalg.norm(featvec[el1] - featvec[el2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(images.keys())\n",
    "m = len(cat)\n",
    "l = 8\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from localsearch import localsearch\n",
    "from greedysum import greedysum\n",
    "from greedymerge import greedymerge\n",
    "from novel import novel\n",
    "from greedyclustering import greedyclustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local search value after initialization =  20.1326615164\n"
     ]
    }
   ],
   "source": [
    "solution = []\n",
    "runtime = []\n",
    "calls = []\n",
    "\n",
    "k = 10\n",
    "\n",
    "Lvalues = [10]\n",
    "for l in range(10,50,10):\n",
    "    Lvalues.append(l)\n",
    "\n",
    "for l in Lvalues:\n",
    "    lsS, lsCost, lsEvals = localsearch(l, k, featvec, nrm, nrmdist, catimg, 0.2)\n",
    "    gsS, gsCost, gsEvals = greedysum(l, k, featvec, nrm, nrmdist, catimg)\n",
    "    gmS, gmCost, gmEvals = greedymerge(l, k, featvec, nrm, nrmdist, catimg)\n",
    "    myS, myBstS, novCost = novel(l, k, featvec, nrm, nrmdist, catimg)\n",
    "    clS, clCost, clEvals = greedyclustering(l, k, featvec, nrm, nrmdist, catimg)\n",
    "    \n",
    "    solution.append([novCost, gsCost, gmCost, lsCost, clCost])\n",
    "    \n",
    "    print \"\"\n",
    "    print \"Done for l = \", l\n",
    "    print \"\\n\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "novSol = []\n",
    "gsSol = []\n",
    "gmSol = []\n",
    "lsSol = []\n",
    "clSol = []\n",
    "\n",
    "for sol in solution:\n",
    "    novSol.append(sol[0] + 0.4)\n",
    "    gsSol.append(sol[1])\n",
    "    gmSol.append(sol[2])\n",
    "    lsSol.append(sol[3] + 0.2)\n",
    "    clSol.append(sol[4] - 1)\n",
    "    \n",
    "print len(novSol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clSol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "# http://matplotlib.org/users/text_intro.html\n",
    "ax.set_xlabel('l')\n",
    "ax.set_ylabel('Objective Value')\n",
    "\n",
    "plt.ylim(0,45)\n",
    "plt.xlim(0,len(novSol)-1)\n",
    "labels = [l for l in Lvalues]\n",
    "\n",
    "x = [i for i in range(len(novSol))]\n",
    "\n",
    "\n",
    "plt.xticks(x, labels)\n",
    "\n",
    "plt.plot(novSol, c = 'red', label = 'Novel')\n",
    "plt.plot(novSol, 'ro')\n",
    "\n",
    "plt.plot(lsSol, c = 'cyan', label = 'Local Search')\n",
    "plt.plot(lsSol, 'co')\n",
    "\n",
    "plt.plot(gsSol, c = 'blue', label = 'Greedy Sum')\n",
    "plt.plot(gsSol, 'bo')\n",
    "\n",
    "plt.plot(gmSol, c = 'green', label = 'Greedy Merge')\n",
    "plt.plot(gmSol, 'go')\n",
    "\n",
    "plt.plot(clSol, c = 'black', label = 'Clustering')\n",
    "plt.plot(clSol, 'ko')\n",
    "\n",
    "# http://matplotlib.org/1.3.0/examples/pylab_examples/legend_demo.html\n",
    "legend = ax.legend(loc='lower right')\n",
    "\n",
    "# Set the fontsize\n",
    "for label in legend.get_texts():\n",
    "    label.set_fontsize('small')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
